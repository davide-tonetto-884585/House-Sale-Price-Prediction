{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import make_blobs\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import plot_tree\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "\n",
    "X_train = pd.read_csv('../data/X_train.csv')\n",
    "X_test = pd.read_csv(\"../data/X_test.csv\")\n",
    "Y_train = pd.read_csv(\"../data/Y_train.csv\")\n",
    "Y_test = pd.read_csv(\"../data/Y_test.csv\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Decision Tree Classifier\n",
    "Proviamo due diversi approcci alla codifica delle etichette derivate dall'intervallo di prezzi Y: eseguiamo un primo tentativo con degli intervalli di prezzo basati sui quantili e di seguito un secondo tentativo usando degli intervalli di prezzo discretizzati con la strategia \"kmeans\".\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CarolaP\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1334: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=3.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "enc1 = KBinsDiscretizer(n_bins=20, encode=\"ordinal\", strategy=\"quantile\")\n",
    "Y_train_binned1 = enc1.fit_transform(Y_train)\n",
    "Y_test_binned1 = enc1.fit_transform(Y_test)\n",
    "\n",
    "Y_train_binned1 = Y_train_binned1.ravel()\n",
    "Y_test_binned1 = Y_test_binned1.ravel()\n",
    "\n",
    "######\n",
    "\n",
    "enc2 = KBinsDiscretizer(n_bins=10, encode=\"ordinal\", strategy=\"kmeans\")\n",
    "Y_train_binned2 = enc2.fit_transform(Y_train)\n",
    "Y_test_binned2 = enc2.fit_transform(Y_test)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Ora proviamo ad applicare un modello DecisionTreeClassifier ai nostri dataset e osserviamo i diversi valori di Train Accuracy e di Test Accuracy che possiamo ottenere al variare dell'iper-parametro max_leaf_nodes del modello."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_max_leaves: 2.000 Train Accuracy: 0.100 - Test Accuracy: 0.101\n",
      "n_max_leaves: 3.000 Train Accuracy: 0.137 - Test Accuracy: 0.135\n",
      "n_max_leaves: 4.000 Train Accuracy: 0.158 - Test Accuracy: 0.164\n",
      "n_max_leaves: 5.000 Train Accuracy: 0.185 - Test Accuracy: 0.191\n",
      "n_max_leaves: 6.000 Train Accuracy: 0.197 - Test Accuracy: 0.203\n",
      "n_max_leaves: 7.000 Train Accuracy: 0.204 - Test Accuracy: 0.205\n",
      "n_max_leaves: 8.000 Train Accuracy: 0.207 - Test Accuracy: 0.203\n",
      "n_max_leaves: 9.000 Train Accuracy: 0.219 - Test Accuracy: 0.206\n",
      "n_max_leaves: 10.000 Train Accuracy: 0.231 - Test Accuracy: 0.213\n",
      "n_max_leaves: 11.000 Train Accuracy: 0.241 - Test Accuracy: 0.210\n",
      "n_max_leaves: 12.000 Train Accuracy: 0.243 - Test Accuracy: 0.210\n",
      "n_max_leaves: 13.000 Train Accuracy: 0.246 - Test Accuracy: 0.205\n",
      "n_max_leaves: 14.000 Train Accuracy: 0.253 - Test Accuracy: 0.215\n",
      "n_max_leaves: 15.000 Train Accuracy: 0.255 - Test Accuracy: 0.217\n",
      "n_max_leaves: 16.000 Train Accuracy: 0.263 - Test Accuracy: 0.217\n",
      "n_max_leaves: 17.000 Train Accuracy: 0.263 - Test Accuracy: 0.215\n",
      "n_max_leaves: 18.000 Train Accuracy: 0.271 - Test Accuracy: 0.218\n",
      "n_max_leaves: 19.000 Train Accuracy: 0.274 - Test Accuracy: 0.224\n",
      "n_max_leaves: 20.000 Train Accuracy: 0.278 - Test Accuracy: 0.227\n",
      "n_max_leaves: 21.000 Train Accuracy: 0.282 - Test Accuracy: 0.229\n",
      "n_max_leaves: 22.000 Train Accuracy: 0.286 - Test Accuracy: 0.230\n",
      "n_max_leaves: 23.000 Train Accuracy: 0.290 - Test Accuracy: 0.232\n",
      "n_max_leaves: 24.000 Train Accuracy: 0.294 - Test Accuracy: 0.237\n",
      "n_max_leaves: 25.000 Train Accuracy: 0.297 - Test Accuracy: 0.241\n",
      "n_max_leaves: 26.000 Train Accuracy: 0.299 - Test Accuracy: 0.241\n",
      "n_max_leaves: 27.000 Train Accuracy: 0.302 - Test Accuracy: 0.244\n",
      "n_max_leaves: 28.000 Train Accuracy: 0.305 - Test Accuracy: 0.241\n",
      "n_max_leaves: 29.000 Train Accuracy: 0.307 - Test Accuracy: 0.239\n",
      "n_max_leaves: 30.000 Train Accuracy: 0.309 - Test Accuracy: 0.247\n",
      "n_max_leaves: 31.000 Train Accuracy: 0.311 - Test Accuracy: 0.251\n",
      "n_max_leaves: 32.000 Train Accuracy: 0.314 - Test Accuracy: 0.254\n",
      "n_max_leaves: 33.000 Train Accuracy: 0.318 - Test Accuracy: 0.249\n",
      "n_max_leaves: 34.000 Train Accuracy: 0.321 - Test Accuracy: 0.249\n",
      "n_max_leaves: 35.000 Train Accuracy: 0.323 - Test Accuracy: 0.247\n",
      "n_max_leaves: 36.000 Train Accuracy: 0.325 - Test Accuracy: 0.253\n",
      "n_max_leaves: 37.000 Train Accuracy: 0.327 - Test Accuracy: 0.251\n",
      "n_max_leaves: 38.000 Train Accuracy: 0.329 - Test Accuracy: 0.251\n",
      "n_max_leaves: 39.000 Train Accuracy: 0.332 - Test Accuracy: 0.253\n",
      "n_max_leaves: 40.000 Train Accuracy: 0.335 - Test Accuracy: 0.253\n",
      "n_max_leaves: 41.000 Train Accuracy: 0.337 - Test Accuracy: 0.253\n",
      "n_max_leaves: 42.000 Train Accuracy: 0.340 - Test Accuracy: 0.249\n",
      "n_max_leaves: 43.000 Train Accuracy: 0.345 - Test Accuracy: 0.249\n",
      "n_max_leaves: 44.000 Train Accuracy: 0.349 - Test Accuracy: 0.249\n",
      "n_max_leaves: 45.000 Train Accuracy: 0.352 - Test Accuracy: 0.246\n",
      "n_max_leaves: 46.000 Train Accuracy: 0.354 - Test Accuracy: 0.251\n",
      "n_max_leaves: 47.000 Train Accuracy: 0.359 - Test Accuracy: 0.251\n",
      "n_max_leaves: 48.000 Train Accuracy: 0.359 - Test Accuracy: 0.251\n",
      "n_max_leaves: 49.000 Train Accuracy: 0.361 - Test Accuracy: 0.251\n",
      "n_max_leaves: 50.000 Train Accuracy: 0.364 - Test Accuracy: 0.249\n",
      "n_max_leaves: 51.000 Train Accuracy: 0.364 - Test Accuracy: 0.249\n",
      "n_max_leaves: 52.000 Train Accuracy: 0.368 - Test Accuracy: 0.251\n",
      "n_max_leaves: 53.000 Train Accuracy: 0.370 - Test Accuracy: 0.251\n",
      "n_max_leaves: 54.000 Train Accuracy: 0.370 - Test Accuracy: 0.249\n",
      "n_max_leaves: 55.000 Train Accuracy: 0.372 - Test Accuracy: 0.251\n",
      "n_max_leaves: 56.000 Train Accuracy: 0.372 - Test Accuracy: 0.244\n",
      "n_max_leaves: 57.000 Train Accuracy: 0.375 - Test Accuracy: 0.244\n",
      "n_max_leaves: 58.000 Train Accuracy: 0.380 - Test Accuracy: 0.247\n",
      "n_max_leaves: 59.000 Train Accuracy: 0.381 - Test Accuracy: 0.249\n",
      "n_max_leaves: 60.000 Train Accuracy: 0.383 - Test Accuracy: 0.249\n",
      "n_max_leaves: 61.000 Train Accuracy: 0.384 - Test Accuracy: 0.249\n",
      "n_max_leaves: 62.000 Train Accuracy: 0.386 - Test Accuracy: 0.249\n",
      "n_max_leaves: 63.000 Train Accuracy: 0.387 - Test Accuracy: 0.247\n",
      "n_max_leaves: 64.000 Train Accuracy: 0.388 - Test Accuracy: 0.246\n",
      "n_max_leaves: 65.000 Train Accuracy: 0.390 - Test Accuracy: 0.247\n",
      "n_max_leaves: 66.000 Train Accuracy: 0.391 - Test Accuracy: 0.246\n",
      "n_max_leaves: 67.000 Train Accuracy: 0.391 - Test Accuracy: 0.246\n",
      "n_max_leaves: 68.000 Train Accuracy: 0.392 - Test Accuracy: 0.246\n",
      "n_max_leaves: 69.000 Train Accuracy: 0.395 - Test Accuracy: 0.246\n",
      "n_max_leaves: 70.000 Train Accuracy: 0.396 - Test Accuracy: 0.244\n",
      "n_max_leaves: 71.000 Train Accuracy: 0.399 - Test Accuracy: 0.247\n",
      "n_max_leaves: 72.000 Train Accuracy: 0.401 - Test Accuracy: 0.246\n",
      "n_max_leaves: 73.000 Train Accuracy: 0.402 - Test Accuracy: 0.246\n",
      "n_max_leaves: 74.000 Train Accuracy: 0.403 - Test Accuracy: 0.246\n",
      "n_max_leaves: 75.000 Train Accuracy: 0.404 - Test Accuracy: 0.242\n",
      "n_max_leaves: 76.000 Train Accuracy: 0.405 - Test Accuracy: 0.242\n",
      "n_max_leaves: 77.000 Train Accuracy: 0.406 - Test Accuracy: 0.242\n",
      "n_max_leaves: 78.000 Train Accuracy: 0.408 - Test Accuracy: 0.244\n",
      "n_max_leaves: 79.000 Train Accuracy: 0.410 - Test Accuracy: 0.244\n",
      "n_max_leaves: 80.000 Train Accuracy: 0.412 - Test Accuracy: 0.242\n",
      "n_max_leaves: 81.000 Train Accuracy: 0.414 - Test Accuracy: 0.246\n",
      "n_max_leaves: 82.000 Train Accuracy: 0.416 - Test Accuracy: 0.246\n",
      "n_max_leaves: 83.000 Train Accuracy: 0.417 - Test Accuracy: 0.246\n",
      "n_max_leaves: 84.000 Train Accuracy: 0.419 - Test Accuracy: 0.246\n",
      "n_max_leaves: 85.000 Train Accuracy: 0.419 - Test Accuracy: 0.246\n",
      "n_max_leaves: 86.000 Train Accuracy: 0.421 - Test Accuracy: 0.246\n",
      "n_max_leaves: 87.000 Train Accuracy: 0.422 - Test Accuracy: 0.244\n",
      "n_max_leaves: 88.000 Train Accuracy: 0.424 - Test Accuracy: 0.246\n",
      "n_max_leaves: 89.000 Train Accuracy: 0.425 - Test Accuracy: 0.246\n",
      "n_max_leaves: 90.000 Train Accuracy: 0.428 - Test Accuracy: 0.247\n",
      "n_max_leaves: 91.000 Train Accuracy: 0.430 - Test Accuracy: 0.246\n",
      "n_max_leaves: 92.000 Train Accuracy: 0.432 - Test Accuracy: 0.244\n",
      "n_max_leaves: 93.000 Train Accuracy: 0.432 - Test Accuracy: 0.242\n",
      "n_max_leaves: 94.000 Train Accuracy: 0.434 - Test Accuracy: 0.242\n",
      "n_max_leaves: 95.000 Train Accuracy: 0.435 - Test Accuracy: 0.242\n",
      "n_max_leaves: 96.000 Train Accuracy: 0.436 - Test Accuracy: 0.241\n",
      "n_max_leaves: 97.000 Train Accuracy: 0.438 - Test Accuracy: 0.241\n",
      "n_max_leaves: 98.000 Train Accuracy: 0.438 - Test Accuracy: 0.242\n",
      "n_max_leaves: 99.000 Train Accuracy: 0.440 - Test Accuracy: 0.242\n",
      "0.25426621160409557 32\n"
     ]
    }
   ],
   "source": [
    "for max_leaves in range(2,100):\n",
    "    # train and predict\n",
    "    dt1 = DecisionTreeClassifier(max_leaf_nodes=max_leaves)\n",
    "    dt1.fit(X_train,Y_train_binned1)\n",
    "\n",
    "    # compute Accuracy\n",
    "    train_acc = accuracy_score(y_true = Y_train_binned1, y_pred = dt1.predict(X_train))\n",
    "    test_acc  = accuracy_score(y_true = Y_test_binned1,  y_pred = dt1.predict(X_test))\n",
    "\n",
    "    print (\"n_max_leaves: {:.3f} Train Accuracy: {:.3f} - Test Accuracy: {:.3f}\".format(max_leaves, train_acc,test_acc))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Si noti che, eseguendo il modello con la divisione dei prezzi in intervalli basati sui quantili, la migliore coppia di performance si ottiene quando l'iper-parametro max_leaf_nodes è pari a 32, in particolare si ha Train accuracy = 0.314 e Test Accuracy = 0.254"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_max_leaves: 2.000 Train Accuracy: 0.333 - Test Accuracy: 0.263\n",
      "n_max_leaves: 3.000 Train Accuracy: 0.363 - Test Accuracy: 0.314\n",
      "n_max_leaves: 4.000 Train Accuracy: 0.391 - Test Accuracy: 0.304\n",
      "n_max_leaves: 5.000 Train Accuracy: 0.429 - Test Accuracy: 0.386\n",
      "n_max_leaves: 6.000 Train Accuracy: 0.447 - Test Accuracy: 0.398\n",
      "n_max_leaves: 7.000 Train Accuracy: 0.472 - Test Accuracy: 0.386\n",
      "n_max_leaves: 8.000 Train Accuracy: 0.500 - Test Accuracy: 0.372\n",
      "n_max_leaves: 9.000 Train Accuracy: 0.509 - Test Accuracy: 0.437\n",
      "n_max_leaves: 10.000 Train Accuracy: 0.512 - Test Accuracy: 0.478\n",
      "n_max_leaves: 11.000 Train Accuracy: 0.512 - Test Accuracy: 0.478\n",
      "n_max_leaves: 12.000 Train Accuracy: 0.532 - Test Accuracy: 0.471\n",
      "n_max_leaves: 13.000 Train Accuracy: 0.540 - Test Accuracy: 0.457\n",
      "n_max_leaves: 14.000 Train Accuracy: 0.554 - Test Accuracy: 0.473\n",
      "n_max_leaves: 15.000 Train Accuracy: 0.566 - Test Accuracy: 0.461\n",
      "n_max_leaves: 16.000 Train Accuracy: 0.571 - Test Accuracy: 0.464\n",
      "n_max_leaves: 17.000 Train Accuracy: 0.586 - Test Accuracy: 0.440\n",
      "n_max_leaves: 18.000 Train Accuracy: 0.592 - Test Accuracy: 0.439\n",
      "n_max_leaves: 19.000 Train Accuracy: 0.602 - Test Accuracy: 0.408\n",
      "n_max_leaves: 20.000 Train Accuracy: 0.611 - Test Accuracy: 0.396\n",
      "n_max_leaves: 21.000 Train Accuracy: 0.618 - Test Accuracy: 0.406\n",
      "n_max_leaves: 22.000 Train Accuracy: 0.618 - Test Accuracy: 0.406\n",
      "n_max_leaves: 23.000 Train Accuracy: 0.620 - Test Accuracy: 0.386\n",
      "n_max_leaves: 24.000 Train Accuracy: 0.620 - Test Accuracy: 0.386\n",
      "n_max_leaves: 25.000 Train Accuracy: 0.620 - Test Accuracy: 0.386\n",
      "n_max_leaves: 26.000 Train Accuracy: 0.625 - Test Accuracy: 0.403\n",
      "n_max_leaves: 27.000 Train Accuracy: 0.628 - Test Accuracy: 0.392\n",
      "n_max_leaves: 28.000 Train Accuracy: 0.635 - Test Accuracy: 0.398\n",
      "n_max_leaves: 29.000 Train Accuracy: 0.637 - Test Accuracy: 0.425\n",
      "n_max_leaves: 30.000 Train Accuracy: 0.641 - Test Accuracy: 0.433\n",
      "n_max_leaves: 31.000 Train Accuracy: 0.645 - Test Accuracy: 0.430\n",
      "n_max_leaves: 32.000 Train Accuracy: 0.646 - Test Accuracy: 0.425\n",
      "n_max_leaves: 33.000 Train Accuracy: 0.648 - Test Accuracy: 0.425\n",
      "n_max_leaves: 34.000 Train Accuracy: 0.650 - Test Accuracy: 0.427\n",
      "n_max_leaves: 35.000 Train Accuracy: 0.653 - Test Accuracy: 0.433\n",
      "n_max_leaves: 36.000 Train Accuracy: 0.656 - Test Accuracy: 0.416\n",
      "n_max_leaves: 37.000 Train Accuracy: 0.658 - Test Accuracy: 0.420\n",
      "n_max_leaves: 38.000 Train Accuracy: 0.664 - Test Accuracy: 0.425\n",
      "n_max_leaves: 39.000 Train Accuracy: 0.667 - Test Accuracy: 0.422\n",
      "n_max_leaves: 40.000 Train Accuracy: 0.674 - Test Accuracy: 0.411\n",
      "n_max_leaves: 41.000 Train Accuracy: 0.677 - Test Accuracy: 0.413\n",
      "n_max_leaves: 42.000 Train Accuracy: 0.679 - Test Accuracy: 0.413\n",
      "n_max_leaves: 43.000 Train Accuracy: 0.681 - Test Accuracy: 0.403\n",
      "n_max_leaves: 44.000 Train Accuracy: 0.683 - Test Accuracy: 0.403\n",
      "n_max_leaves: 45.000 Train Accuracy: 0.686 - Test Accuracy: 0.406\n",
      "n_max_leaves: 46.000 Train Accuracy: 0.687 - Test Accuracy: 0.401\n",
      "n_max_leaves: 47.000 Train Accuracy: 0.689 - Test Accuracy: 0.399\n",
      "n_max_leaves: 48.000 Train Accuracy: 0.689 - Test Accuracy: 0.394\n",
      "n_max_leaves: 49.000 Train Accuracy: 0.692 - Test Accuracy: 0.392\n",
      "n_max_leaves: 50.000 Train Accuracy: 0.694 - Test Accuracy: 0.394\n",
      "n_max_leaves: 51.000 Train Accuracy: 0.695 - Test Accuracy: 0.392\n",
      "n_max_leaves: 52.000 Train Accuracy: 0.697 - Test Accuracy: 0.394\n",
      "n_max_leaves: 53.000 Train Accuracy: 0.697 - Test Accuracy: 0.394\n",
      "n_max_leaves: 54.000 Train Accuracy: 0.697 - Test Accuracy: 0.394\n",
      "n_max_leaves: 55.000 Train Accuracy: 0.699 - Test Accuracy: 0.394\n",
      "n_max_leaves: 56.000 Train Accuracy: 0.700 - Test Accuracy: 0.399\n",
      "n_max_leaves: 57.000 Train Accuracy: 0.702 - Test Accuracy: 0.399\n",
      "n_max_leaves: 58.000 Train Accuracy: 0.704 - Test Accuracy: 0.399\n",
      "n_max_leaves: 59.000 Train Accuracy: 0.705 - Test Accuracy: 0.401\n",
      "n_max_leaves: 60.000 Train Accuracy: 0.705 - Test Accuracy: 0.401\n",
      "n_max_leaves: 61.000 Train Accuracy: 0.709 - Test Accuracy: 0.401\n",
      "n_max_leaves: 62.000 Train Accuracy: 0.710 - Test Accuracy: 0.403\n",
      "n_max_leaves: 63.000 Train Accuracy: 0.712 - Test Accuracy: 0.404\n",
      "n_max_leaves: 64.000 Train Accuracy: 0.712 - Test Accuracy: 0.404\n",
      "n_max_leaves: 65.000 Train Accuracy: 0.712 - Test Accuracy: 0.404\n",
      "n_max_leaves: 66.000 Train Accuracy: 0.714 - Test Accuracy: 0.413\n",
      "n_max_leaves: 67.000 Train Accuracy: 0.716 - Test Accuracy: 0.418\n",
      "n_max_leaves: 68.000 Train Accuracy: 0.718 - Test Accuracy: 0.415\n",
      "n_max_leaves: 69.000 Train Accuracy: 0.719 - Test Accuracy: 0.415\n",
      "n_max_leaves: 70.000 Train Accuracy: 0.719 - Test Accuracy: 0.415\n",
      "n_max_leaves: 71.000 Train Accuracy: 0.721 - Test Accuracy: 0.413\n",
      "n_max_leaves: 72.000 Train Accuracy: 0.721 - Test Accuracy: 0.411\n",
      "n_max_leaves: 73.000 Train Accuracy: 0.721 - Test Accuracy: 0.411\n",
      "n_max_leaves: 74.000 Train Accuracy: 0.723 - Test Accuracy: 0.408\n",
      "n_max_leaves: 75.000 Train Accuracy: 0.723 - Test Accuracy: 0.408\n",
      "n_max_leaves: 76.000 Train Accuracy: 0.723 - Test Accuracy: 0.410\n",
      "n_max_leaves: 77.000 Train Accuracy: 0.726 - Test Accuracy: 0.408\n",
      "n_max_leaves: 78.000 Train Accuracy: 0.728 - Test Accuracy: 0.408\n",
      "n_max_leaves: 79.000 Train Accuracy: 0.730 - Test Accuracy: 0.410\n",
      "n_max_leaves: 80.000 Train Accuracy: 0.731 - Test Accuracy: 0.411\n",
      "n_max_leaves: 81.000 Train Accuracy: 0.733 - Test Accuracy: 0.410\n",
      "n_max_leaves: 82.000 Train Accuracy: 0.733 - Test Accuracy: 0.408\n",
      "n_max_leaves: 83.000 Train Accuracy: 0.734 - Test Accuracy: 0.408\n",
      "n_max_leaves: 84.000 Train Accuracy: 0.734 - Test Accuracy: 0.408\n",
      "n_max_leaves: 85.000 Train Accuracy: 0.735 - Test Accuracy: 0.410\n",
      "n_max_leaves: 86.000 Train Accuracy: 0.736 - Test Accuracy: 0.406\n",
      "n_max_leaves: 87.000 Train Accuracy: 0.736 - Test Accuracy: 0.408\n",
      "n_max_leaves: 88.000 Train Accuracy: 0.738 - Test Accuracy: 0.408\n",
      "n_max_leaves: 89.000 Train Accuracy: 0.739 - Test Accuracy: 0.408\n",
      "n_max_leaves: 90.000 Train Accuracy: 0.739 - Test Accuracy: 0.410\n",
      "n_max_leaves: 91.000 Train Accuracy: 0.741 - Test Accuracy: 0.411\n",
      "n_max_leaves: 92.000 Train Accuracy: 0.743 - Test Accuracy: 0.411\n",
      "n_max_leaves: 93.000 Train Accuracy: 0.745 - Test Accuracy: 0.411\n",
      "n_max_leaves: 94.000 Train Accuracy: 0.747 - Test Accuracy: 0.404\n",
      "n_max_leaves: 95.000 Train Accuracy: 0.748 - Test Accuracy: 0.406\n",
      "n_max_leaves: 96.000 Train Accuracy: 0.749 - Test Accuracy: 0.410\n",
      "n_max_leaves: 97.000 Train Accuracy: 0.751 - Test Accuracy: 0.413\n",
      "n_max_leaves: 98.000 Train Accuracy: 0.752 - Test Accuracy: 0.404\n",
      "n_max_leaves: 99.000 Train Accuracy: 0.752 - Test Accuracy: 0.403\n",
      "0.4778156996587031 10\n"
     ]
    }
   ],
   "source": [
    "for max_leaves in range(2,100):\n",
    "    # train and predict\n",
    "    dt2 = DecisionTreeClassifier(max_leaf_nodes=max_leaves)\n",
    "    dt2.fit(X_train,Y_train_binned2)\n",
    "\n",
    "    # compute Accuracy\n",
    "    train_acc = accuracy_score(y_true = Y_train_binned2, y_pred = dt2.predict(X_train))\n",
    "    test_acc  = accuracy_score(y_true = Y_test_binned2,  y_pred = dt2.predict(X_test))\n",
    "\n",
    "    print (\"n_max_leaves: {:.3f} Train Accuracy: {:.3f} - Test Accuracy: {:.3f}\".format(max_leaves, train_acc,test_acc))\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Si noti che, eseguendo il modello con la divisione dei prezzi in intervalli discretizzati con la strategia \"kmeans\", la migliore coppia di performance si ottiene quando l'iper-parametro max_leaf_nodes è pari a 10, in particolare si ha Train accuracy = 0.512 e Test Accuracy = 0.478"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    " In conclusione possiamo dire che le suddette performance non sono soddisfacenti e pertanto proseguiamo lo studio del dataset ai fini di prevedere il prezzo delle proprietà immobiliari in esso contenuto."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
