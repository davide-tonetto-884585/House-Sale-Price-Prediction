{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### Random Forest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Discretizzazione\n",
    "Andiamo a definire delle classi sul prezzo per poter usare il classificatore"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "X_train = pd.read_csv('../data/X_train.csv')\n",
    "X_test = pd.read_csv('../data/X_test.csv')\n",
    "Y_train = pd.read_csv('../data/Y_train.csv')\n",
    "Y_test = pd.read_csv('../data/Y_test.csv')\n",
    "\n",
    "enc = KBinsDiscretizer(n_bins=20, encode=\"ordinal\", strategy=\"quantile\")\n",
    "Y_train_binned = enc.fit_transform(Y_train)\n",
    "Y_test_binned = enc.fit_transform(Y_test)\n",
    "\n",
    "Y_train_binned = Y_train_binned.ravel()\n",
    "Y_test_binned=Y_test_binned.ravel()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Random Forest"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N trees 27: train accuracy: 1.0, test accuracy: 0.2832764505119454\n",
      "Fitting 8 folds for each of 1 candidates, totalling 8 fits\n",
      "Grid: train accuracy: 27, test accuracy: 0.9991467576791809\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Singleton array array(None, dtype=object) cannot be considered a valid collection.",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [2], line 45\u001B[0m\n\u001B[0;32m     42\u001B[0m         fig\u001B[38;5;241m.\u001B[39mset_figwidth(\u001B[38;5;241m12\u001B[39m)\n\u001B[0;32m     43\u001B[0m         fig\u001B[38;5;241m.\u001B[39mset_figheight(\u001B[38;5;241m12\u001B[39m)\n\u001B[1;32m---> 45\u001B[0m \u001B[43mRandomForestSelector\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn [2], line 36\u001B[0m, in \u001B[0;36mRandomForestSelector\u001B[1;34m()\u001B[0m\n\u001B[0;32m     34\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mGrid: train accuracy: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m, test accuracy: \u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mformat(t,acc_train,acc_test))\n\u001B[0;32m     35\u001B[0m \u001B[38;5;28mprint\u001B[39m()\n\u001B[1;32m---> 36\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[43mgrid\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscore\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_test\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     38\u001B[0m cm \u001B[38;5;241m=\u001B[39m ConfusionMatrixDisplay\u001B[38;5;241m.\u001B[39mfrom_estimator(\n\u001B[0;32m     39\u001B[0m     estimator\u001B[38;5;241m=\u001B[39mgrid,\n\u001B[0;32m     40\u001B[0m     X\u001B[38;5;241m=\u001B[39mX_test, y\u001B[38;5;241m=\u001B[39mY_test_binned)\n\u001B[0;32m     41\u001B[0m fig \u001B[38;5;241m=\u001B[39m cm\u001B[38;5;241m.\u001B[39max_\u001B[38;5;241m.\u001B[39mget_figure()\n",
      "File \u001B[1;32m~\\py_venvs\\progetto_DWM_venv\\lib\\site-packages\\sklearn\\model_selection\\_search.py:452\u001B[0m, in \u001B[0;36mBaseSearchCV.score\u001B[1;34m(self, X, y)\u001B[0m\n\u001B[0;32m    449\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m scorer(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbest_estimator_, X, y)\n\u001B[0;32m    451\u001B[0m \u001B[38;5;66;03m# callable\u001B[39;00m\n\u001B[1;32m--> 452\u001B[0m score \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscorer_\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbest_estimator_\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    453\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmultimetric_:\n\u001B[0;32m    454\u001B[0m     score \u001B[38;5;241m=\u001B[39m score[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrefit]\n",
      "File \u001B[1;32m~\\py_venvs\\progetto_DWM_venv\\lib\\site-packages\\sklearn\\metrics\\_scorer.py:219\u001B[0m, in \u001B[0;36m_BaseScorer.__call__\u001B[1;34m(self, estimator, X, y_true, sample_weight)\u001B[0m\n\u001B[0;32m    196\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, estimator, X, y_true, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    197\u001B[0m     \u001B[38;5;124;03m\"\"\"Evaluate predicted target values for X relative to y_true.\u001B[39;00m\n\u001B[0;32m    198\u001B[0m \n\u001B[0;32m    199\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    217\u001B[0m \u001B[38;5;124;03m        Score function applied to prediction of estimator on X.\u001B[39;00m\n\u001B[0;32m    218\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 219\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_score\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    220\u001B[0m \u001B[43m        \u001B[49m\u001B[43mpartial\u001B[49m\u001B[43m(\u001B[49m\u001B[43m_cached_call\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    221\u001B[0m \u001B[43m        \u001B[49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    222\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    223\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    224\u001B[0m \u001B[43m        \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    225\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\py_venvs\\progetto_DWM_venv\\lib\\site-packages\\sklearn\\metrics\\_scorer.py:267\u001B[0m, in \u001B[0;36m_PredictScorer._score\u001B[1;34m(self, method_caller, estimator, X, y_true, sample_weight)\u001B[0m\n\u001B[0;32m    263\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sign \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_score_func(\n\u001B[0;32m    264\u001B[0m         y_true, y_pred, sample_weight\u001B[38;5;241m=\u001B[39msample_weight, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_kwargs\n\u001B[0;32m    265\u001B[0m     )\n\u001B[0;32m    266\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 267\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sign \u001B[38;5;241m*\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_score_func(y_true, y_pred, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_kwargs)\n",
      "File \u001B[1;32m~\\py_venvs\\progetto_DWM_venv\\lib\\site-packages\\sklearn\\metrics\\_regression.py:442\u001B[0m, in \u001B[0;36mmean_squared_error\u001B[1;34m(y_true, y_pred, sample_weight, multioutput, squared)\u001B[0m\n\u001B[0;32m    382\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmean_squared_error\u001B[39m(\n\u001B[0;32m    383\u001B[0m     y_true, y_pred, \u001B[38;5;241m*\u001B[39m, sample_weight\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, multioutput\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124muniform_average\u001B[39m\u001B[38;5;124m\"\u001B[39m, squared\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m    384\u001B[0m ):\n\u001B[0;32m    385\u001B[0m     \u001B[38;5;124;03m\"\"\"Mean squared error regression loss.\u001B[39;00m\n\u001B[0;32m    386\u001B[0m \n\u001B[0;32m    387\u001B[0m \u001B[38;5;124;03m    Read more in the :ref:`User Guide <mean_squared_error>`.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    440\u001B[0m \u001B[38;5;124;03m    0.825...\u001B[39;00m\n\u001B[0;32m    441\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 442\u001B[0m     y_type, y_true, y_pred, multioutput \u001B[38;5;241m=\u001B[39m \u001B[43m_check_reg_targets\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    443\u001B[0m \u001B[43m        \u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_pred\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmultioutput\u001B[49m\n\u001B[0;32m    444\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    445\u001B[0m     check_consistent_length(y_true, y_pred, sample_weight)\n\u001B[0;32m    446\u001B[0m     output_errors \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39maverage((y_true \u001B[38;5;241m-\u001B[39m y_pred) \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39m \u001B[38;5;241m2\u001B[39m, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, weights\u001B[38;5;241m=\u001B[39msample_weight)\n",
      "File \u001B[1;32m~\\py_venvs\\progetto_DWM_venv\\lib\\site-packages\\sklearn\\metrics\\_regression.py:101\u001B[0m, in \u001B[0;36m_check_reg_targets\u001B[1;34m(y_true, y_pred, multioutput, dtype)\u001B[0m\n\u001B[0;32m     67\u001B[0m \u001B[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same regression task.\u001B[39;00m\n\u001B[0;32m     68\u001B[0m \n\u001B[0;32m     69\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     98\u001B[0m \u001B[38;5;124;03m    correct keyword.\u001B[39;00m\n\u001B[0;32m     99\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    100\u001B[0m check_consistent_length(y_true, y_pred)\n\u001B[1;32m--> 101\u001B[0m y_true \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43my_true\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mensure_2d\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    102\u001B[0m y_pred \u001B[38;5;241m=\u001B[39m check_array(y_pred, ensure_2d\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m, dtype\u001B[38;5;241m=\u001B[39mdtype)\n\u001B[0;32m    104\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m y_true\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[1;32m~\\py_venvs\\progetto_DWM_venv\\lib\\site-packages\\sklearn\\utils\\validation.py:907\u001B[0m, in \u001B[0;36mcheck_array\u001B[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[0;32m    899\u001B[0m         _assert_all_finite(\n\u001B[0;32m    900\u001B[0m             array,\n\u001B[0;32m    901\u001B[0m             input_name\u001B[38;5;241m=\u001B[39minput_name,\n\u001B[0;32m    902\u001B[0m             estimator_name\u001B[38;5;241m=\u001B[39mestimator_name,\n\u001B[0;32m    903\u001B[0m             allow_nan\u001B[38;5;241m=\u001B[39mforce_all_finite \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mallow-nan\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m    904\u001B[0m         )\n\u001B[0;32m    906\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m ensure_min_samples \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 907\u001B[0m     n_samples \u001B[38;5;241m=\u001B[39m \u001B[43m_num_samples\u001B[49m\u001B[43m(\u001B[49m\u001B[43marray\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    908\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m n_samples \u001B[38;5;241m<\u001B[39m ensure_min_samples:\n\u001B[0;32m    909\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m    910\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFound array with \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m sample(s) (shape=\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m) while a\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    911\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m minimum of \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m is required\u001B[39m\u001B[38;5;132;01m%s\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    912\u001B[0m             \u001B[38;5;241m%\u001B[39m (n_samples, array\u001B[38;5;241m.\u001B[39mshape, ensure_min_samples, context)\n\u001B[0;32m    913\u001B[0m         )\n",
      "File \u001B[1;32m~\\py_venvs\\progetto_DWM_venv\\lib\\site-packages\\sklearn\\utils\\validation.py:325\u001B[0m, in \u001B[0;36m_num_samples\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m    323\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(x, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mshape\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m x\u001B[38;5;241m.\u001B[39mshape \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    324\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(x\u001B[38;5;241m.\u001B[39mshape) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m--> 325\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\n\u001B[0;32m    326\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mSingleton array \u001B[39m\u001B[38;5;132;01m%r\u001B[39;00m\u001B[38;5;124m cannot be considered a valid collection.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m x\n\u001B[0;32m    327\u001B[0m         )\n\u001B[0;32m    328\u001B[0m     \u001B[38;5;66;03m# Check that shape is returning an integer or default to len\u001B[39;00m\n\u001B[0;32m    329\u001B[0m     \u001B[38;5;66;03m# Dask dataframes may not return numeric shape[0] value\u001B[39;00m\n\u001B[0;32m    330\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(x\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m0\u001B[39m], numbers\u001B[38;5;241m.\u001B[39mIntegral):\n",
      "\u001B[1;31mTypeError\u001B[0m: Singleton array array(None, dtype=object) cannot be considered a valid collection."
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "def RandomForestSelector():\n",
    "    #Tuning della random Forest classifier\n",
    "    n_trees= [27]\n",
    "    #[5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,25,27,30]\n",
    "\n",
    "    max_tree = 5\n",
    "    max_acc = 0\n",
    "\n",
    "    for t in n_trees:\n",
    "        rf=RandomForestClassifier(n_estimators=27)\n",
    "        rf.fit(X_train,Y_train_binned)\n",
    "        acc_train = accuracy_score(y_true=Y_train_binned, y_pred=rf.predict(X_train))\n",
    "        acc_test  = accuracy_score(y_true=Y_test_binned, y_pred=rf.predict(X_test))\n",
    "        print('N trees {}: train accuracy: {}, test accuracy: {}'.format(t,acc_train,acc_test))\n",
    "\n",
    "        properties={\n",
    "            #min_sample_leaf piu piccolo possibile\n",
    "            #max feature piu grande possibile\n",
    "            #min_samples_split piu' piccolo possibile\n",
    "            #max_leaf_nodes piu' grande possibile\n",
    "            #max_samples piu' alto possibile\n",
    "        }\n",
    "\n",
    "        grid=GridSearchCV(rf,properties,scoring=\"neg_mean_squared_error\",cv=8,n_jobs=-1,return_train_score=True,verbose=2, refit=True)\n",
    "        grid.fit(X_train,Y_train_binned)\n",
    "        acc_train = accuracy_score(y_true=Y_train_binned, y_pred=grid.predict(X_train))\n",
    "        acc_test  = accuracy_score(y_true=Y_test_binned, y_pred=grid.predict(X_test))\n",
    "\n",
    "        print('Grid: train accuracy: {}, test accuracy: {}'.format(t,acc_train,acc_test))\n",
    "        print()\n",
    "        print(grid.score(X_test))\n",
    "\n",
    "        cm = ConfusionMatrixDisplay.from_estimator(\n",
    "            estimator=grid,\n",
    "            X=X_test, y=Y_test_binned)\n",
    "        fig = cm.ax_.get_figure()\n",
    "        fig.set_figwidth(12)\n",
    "        fig.set_figheight(12)\n",
    "\n",
    "RandomForestSelector()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
